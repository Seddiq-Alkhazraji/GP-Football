{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "fe397786-0242-47a8-9681-ee42c2a0be5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FILE = \"scout_outfield.csv\" \n",
    "MODEL_FILE = \"knn_similarity.pkl\"\n",
    "SCALER_FILE = \"knn_scaler.pkl\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "268c63cd-7a08-4455-acb0-aca76c405ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“‚ Loading Scout Data...\n",
      "ðŸ§¬ Selected 22 Features.\n",
      "ðŸ“‰ Applying PCA (Dimensionality Reduction)...\n",
      "   Reduced dimensions from 22 to 17\n",
      "ðŸ§  Training KNN Engine...\n",
      "âœ… Model Trained with PCA & Saved!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "DATA_FILE = \"scout_outfield.csv\"\n",
    "MODEL_FILE = \"knn_similarity.pkl\"\n",
    "SCALER_FILE = \"knn_scaler.pkl\"\n",
    "PCA_FILE = \"knn_pca.pkl\"          \n",
    "FEATURE_FILE = \"dna_features.json\"\n",
    "\n",
    "# --- 1. PRECISE FEATURE SELECTION ---\n",
    "DNA_FEATURES = [\n",
    "    # SCORING & THREAT\n",
    "    'npxG_Per', 'Sh_per_90_Standard', 'SoT_percent_Standard', 'Att Pen_Touches_Per90',\n",
    "    \n",
    "    # CREATION\n",
    "    'PrgP_Per90', 'KP_Per90', 'xA_Expected', 'Cmp_percent_Total', 'Cmp_Long_Per90',\n",
    "    'Final_Third_Per90', 'PPA_Per90', 'CrsPA_Per90',\n",
    "    \n",
    "    # DRIBBLING / CARRYING\n",
    "    'PrgC_Carries_Per90', 'PrgDist_Carries_Per90', 'Succ_Take_Per90', 'Dis_Carries',\n",
    "    \n",
    "    # DEFENSE \n",
    "    'TklW_Tackles_Per90', 'Int_Def_Per90', 'Blocks_Blocks_Per90', \n",
    "    'Won_percent_Aerial', 'Recov_Per90', 'Clr_Per90'\n",
    "]\n",
    "\n",
    "# --- 2. TRAINING PIPELINE ---\n",
    "if os.path.exists(DATA_FILE):\n",
    "    print(\"ðŸ“‚ Loading Scout Data...\")\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    \n",
    "    # Select only existing columns\n",
    "    active_features = [c for c in DNA_FEATURES if c in df.columns]\n",
    "    print(f\"ðŸ§¬ Selected {len(active_features)} Features.\")\n",
    "\n",
    "    # A. SCALING \n",
    "    scaler = RobustScaler()\n",
    "    X = df[active_features].fillna(0)\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "    # B. PCA \n",
    "    print(\"ðŸ“‰ Applying PCA (Dimensionality Reduction)...\")\n",
    "    pca = PCA(n_components=0.95) \n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    print(f\"   Reduced dimensions from {X_scaled.shape[1]} to {X_pca.shape[1]}\")\n",
    "\n",
    "    # C. KNN \n",
    "    print(\"ðŸ§  Training KNN Engine...\")\n",
    "    knn = NearestNeighbors(n_neighbors=5, metric='cosine', algorithm='brute')\n",
    "    knn.fit(X_pca)\n",
    "\n",
    "    # --- SAVE ---\n",
    "    with open(MODEL_FILE, 'wb') as f: pickle.dump(knn, f)\n",
    "    with open(SCALER_FILE, 'wb') as f: pickle.dump(scaler, f)\n",
    "    with open(PCA_FILE, 'wb') as f: pickle.dump(pca, f) # Save PCA\n",
    "    with open(FEATURE_FILE, 'w') as f: json.dump(active_features, f)\n",
    "        \n",
    "    print(\"âœ… Model Trained with PCA & Saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "5f86a05c-b9df-4db7-9ddd-ad43cd39957b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ§ª STARTING SMART EVALUATION...\n",
      "   Analyzing 500 players using Tactical Overlap Map...\n",
      "----------------------------------------\n",
      "âœ… TACTICAL CONSISTENCY SCORE: 66.4%\n",
      "ðŸ”¹ Perfect Position Matches:     54.8%\n",
      "----------------------------------------\n",
      "   âœ… ACCEPTABLE: Good logic, some hybrid overlaps.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "# CONFIG\n",
    "DATA_FILE = \"scout_outfield.csv\"\n",
    "MODEL_FILE = \"knn_similarity.pkl\"\n",
    "SCALER_FILE = \"knn_scaler.pkl\"\n",
    "PCA_FILE = \"knn_pca.pkl\"         \n",
    "FEATURE_FILE = \"dna_features.json\"\n",
    "\n",
    "# --- TACTICAL OVERLAP MAP ---\n",
    "OVERLAP_MAP = {\n",
    "    'CB':  {'CB': 1.0, 'CDM': 0.5, 'RB': 0.2, 'LB': 0.2},\n",
    "    'LB':  {'LB': 1.0, 'RB': 1.0, 'LWB': 1.0, 'LM': 0.5, 'CB': 0.2},\n",
    "    'RB':  {'RB': 1.0, 'LB': 1.0, 'RWB': 1.0, 'RM': 0.5, 'CB': 0.2},\n",
    "    'CDM': {'CDM': 1.0, 'CM': 0.8, 'CB': 0.5},\n",
    "    'CM':  {'CM': 1.0, 'CDM': 0.8, 'CAM': 0.6},\n",
    "    'CAM': {'CAM': 1.0, 'CM': 0.6, 'LW': 0.4, 'RW': 0.4, 'ST': 0.2},\n",
    "    'LM':  {'LM': 1.0, 'RM': 1.0, 'LW': 0.8, 'LB': 0.5},\n",
    "    'RM':  {'RM': 1.0, 'LM': 1.0, 'RW': 0.8, 'RB': 0.5},\n",
    "    'LW':  {'LW': 1.0, 'RW': 1.0, 'LM': 0.8, 'ST': 0.4, 'CAM': 0.4},\n",
    "    'RW':  {'RW': 1.0, 'LW': 1.0, 'RM': 0.8, 'ST': 0.4, 'CAM': 0.4},\n",
    "    'ST':  {'ST': 1.0, 'CF': 1.0, 'LW': 0.4, 'RW': 0.4},\n",
    "}\n",
    "\n",
    "def evaluate_smart_accuracy():\n",
    "    print(\"ðŸ§ª STARTING SMART EVALUATION...\")\n",
    "    \n",
    "    # 1. Load Resources\n",
    "    try:\n",
    "        df = pd.read_csv(DATA_FILE)\n",
    "        with open(MODEL_FILE, 'rb') as f: knn = pickle.load(f)\n",
    "        with open(SCALER_FILE, 'rb') as f: scaler = pickle.load(f)\n",
    "        with open(PCA_FILE, 'rb') as f: pca = pickle.load(f)\n",
    "        with open(FEATURE_FILE, 'r') as f: features = json.load(f)\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Files missing. Run training first.\")\n",
    "        return\n",
    "\n",
    "    # 2. Process Data\n",
    "    X = df[features].fillna(0)\n",
    "    X_scaled = scaler.transform(X)\n",
    "    X_final = pca.transform(X_scaled) \n",
    "\n",
    "    # 3. Test Loop\n",
    "    if 'main_pos' not in df.columns:\n",
    "        print(\"âŒ 'main_pos' column missing.\")\n",
    "        return\n",
    "\n",
    "    valid_df = df.dropna(subset=['main_pos'])\n",
    "    sample = valid_df.sample(min(500, len(valid_df)), random_state=42)\n",
    "    \n",
    "    total_score = 0\n",
    "    total_neighbors = 0\n",
    "    perfect_matches = 0\n",
    "    \n",
    "    print(f\"   Analyzing {len(sample)} players using Tactical Overlap Map...\")\n",
    "    \n",
    "    for idx, row in sample.iterrows():\n",
    "        # Get Target Pos\n",
    "        target_pos = str(row['main_pos']).split(',')[0].strip()\n",
    "        \n",
    "        # Validate target pos exists in map\n",
    "        if target_pos not in OVERLAP_MAP: continue\n",
    "        \n",
    "        # Get Neighbors\n",
    "        mat_idx = df.index.get_loc(idx)\n",
    "        \n",
    "        # --- FIXED LINES BELOW ---\n",
    "        dists, inds = knn.kneighbors([X_final[mat_idx]], n_neighbors=6)\n",
    "        \n",
    "        # Check Neighbors (Skip self at index 0)\n",
    "        for i in range(1, len(inds[0])): \n",
    "            n_idx = inds[0][i]\n",
    "            n_pos = str(df.iloc[n_idx]['main_pos']).split(',')[0].strip()\n",
    "            \n",
    "            # --- SCORING ---\n",
    "            points = 0\n",
    "            \n",
    "            # 1. Direct Lookup in Map\n",
    "            allowed = OVERLAP_MAP.get(target_pos, {})\n",
    "            if n_pos in allowed:\n",
    "                points = allowed[n_pos]\n",
    "            \n",
    "            # 2. Fallback: Exact String Match\n",
    "            elif n_pos == target_pos:\n",
    "                points = 1.0\n",
    "\n",
    "            total_score += points\n",
    "            total_neighbors += 1\n",
    "            if points == 1.0: perfect_matches += 1\n",
    "\n",
    "    # 4. Results\n",
    "    if total_neighbors == 0:\n",
    "        print(\"âš ï¸ No valid neighbors analyzed.\")\n",
    "        return\n",
    "\n",
    "    avg_score = (total_score / total_neighbors) * 100\n",
    "    perfect_rate = (perfect_matches / total_neighbors) * 100\n",
    "    \n",
    "    print(\"-\" * 40)\n",
    "    print(f\"âœ… TACTICAL CONSISTENCY SCORE: {avg_score:.1f}%\")\n",
    "    print(f\"ðŸ”¹ Perfect Position Matches:     {perfect_rate:.1f}%\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if avg_score > 75: print(\"   ðŸš€ EXCELLENT: The model understands player roles.\")\n",
    "    elif avg_score > 60: print(\"   âœ… ACCEPTABLE: Good logic, some hybrid overlaps.\")\n",
    "    else: print(\"   âš ï¸ POOR: Still confusing distinct roles.\")\n",
    "\n",
    "evaluate_smart_accuracy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5e1d0dd4-621c-47ff-8dce-3208c4a1594c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ§ RUNNING SANITY CHECKS...\n",
      "\n",
      "Player: erling haaland (ST)\n",
      "Similar to:\n",
      "   -> alvaro morata (ST) - 95.9% Match\n",
      "   -> goncalo ramos (ST) - 95.6% Match\n",
      "   -> robert lewandowski (ST) - 95.5% Match\n",
      "\n",
      "Player: trent alexander-arnold (RB)\n",
      "Similar to:\n",
      "   -> hakan calhanoglu (CDM) - 97.5% Match\n",
      "   -> oscar mingueza (RB) - 96.6% Match\n",
      "   -> joshua kimmich (CDM) - 96.2% Match\n",
      "\n",
      "Player: kevin de bruyne (CM)\n",
      "Similar to:\n",
      "   -> alex baena (CAM) - 95.6% Match\n",
      "   -> james maddison (CM) - 94.9% Match\n",
      "   -> michael olise (RM) - 94.1% Match\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import json\n",
    "import os\n",
    "\n",
    "# CONFIG\n",
    "DATA_FILE = \"scout_outfield.csv\"\n",
    "MODEL_FILE = \"knn_similarity.pkl\"\n",
    "SCALER_FILE = \"knn_scaler.pkl\"\n",
    "FEATURE_FILE = \"dna_features.json\" # <--- The file we just saved\n",
    "\n",
    "def sanity_check():\n",
    "    test_cases = [\"Erling Haaland\", \"Trent Alexander-Arnold\", \"Kevin de bruyne\"]\n",
    "    \n",
    "    # 1. Load Data\n",
    "    df = pd.read_csv(DATA_FILE)\n",
    "    df['search_key'] = df['Player'].astype(str).str.lower().str.strip()\n",
    "    \n",
    "    # 2. Load Model, Scaler AND Feature List\n",
    "    try:\n",
    "        with open(MODEL_FILE, 'rb') as f: knn = pickle.load(f)\n",
    "        with open(SCALER_FILE, 'rb') as f: scaler = pickle.load(f)\n",
    "        with open(FEATURE_FILE, 'r') as f: saved_features = json.load(f) # <--- Load the list\n",
    "    except FileNotFoundError:\n",
    "        print(\"âŒ Error: Missing model files. Run the training script first.\")\n",
    "        return\n",
    "\n",
    "    # 3. Prepare Data Matrix\n",
    "    X_scaled = scaler.transform(df[saved_features].fillna(0))\n",
    "\n",
    "    print(\"\\nðŸ§ RUNNING SANITY CHECKS...\")\n",
    "    \n",
    "    for player in test_cases:\n",
    "        s_key = player.lower().strip()\n",
    "        found = df[df['search_key'] == s_key]\n",
    "        \n",
    "        if found.empty:\n",
    "            print(f\"âš ï¸ Skipped {player} (Not in database)\")\n",
    "            continue\n",
    "            \n",
    "        idx = found.index[0]\n",
    "        mtx_idx = df.index.get_loc(idx)\n",
    "        \n",
    "        # Predict\n",
    "        dists, inds = knn.kneighbors([X_scaled[mtx_idx]], n_neighbors=4)\n",
    "        \n",
    "        # Print Results\n",
    "        p_row = found.iloc[0]\n",
    "        pos = p_row['main_pos'] if 'main_pos' in p_row else p_row.get('Pos', '?')\n",
    "        \n",
    "        print(f\"\\nPlayer: {p_row['Player']} ({pos})\")\n",
    "        print(f\"Similar to:\")\n",
    "        for i in range(1, 4):\n",
    "            n_idx = inds[0][i]\n",
    "            neighbor = df.iloc[n_idx]\n",
    "            n_pos = neighbor['main_pos'] if 'main_pos' in neighbor else neighbor.get('Pos', '?')\n",
    "            \n",
    "            # Convert cosine distance to similarity %\n",
    "            sim_score = (1 - dists[0][i]) * 100\n",
    "            print(f\"   -> {neighbor['Player']} ({n_pos}) - {sim_score:.1f}% Match\")\n",
    "\n",
    "sanity_check()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d4c0a4-d314-4f5c-a337-dc441f65fe1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
